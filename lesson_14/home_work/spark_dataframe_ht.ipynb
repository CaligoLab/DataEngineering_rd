{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-24T10:59:06.012496Z",
     "start_time": "2024-05-24T10:59:05.882280Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F, types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-05-24T10:59:14.101141Z",
     "start_time": "2024-05-24T10:59:08.172944Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/24 13:59:11 WARN Utils: Your hostname, MacBook-Pro-Almin.local resolves to a loopback address: 127.0.0.1; using 192.168.68.103 instead (on interface en0)\n",
      "24/05/24 13:59:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/24 13:59:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master('local[*]').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T10:59:16.656667Z",
     "start_time": "2024-05-24T10:59:16.652348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.1\n"
     ]
    }
   ],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T10:59:33.935295Z",
     "start_time": "2024-05-24T10:59:21.042853Z"
    }
   },
   "outputs": [],
   "source": [
    "actor_df = spark.read.csv('./data/actor.csv', header=True, inferSchema=True)\n",
    "address_df = spark.read.csv('./data/address.csv', header=True, inferSchema=True)\n",
    "category_df = spark.read.csv('./data/category.csv', header=True, inferSchema=True)\n",
    "city_df = spark.read.csv('./data/city.csv', header=True, inferSchema=True)\n",
    "country_df = spark.read.csv('./data/country.csv', header=True, inferSchema=True)\n",
    "customer_df = spark.read.csv('./data/customer.csv', header=True, inferSchema=True)\n",
    "film_df = spark.read.csv('./data/film.csv', header=True, inferSchema=True)\n",
    "film_actor_df = spark.read.csv('./data/film_actor.csv', header=True, inferSchema=True)\n",
    "film_category_df = spark.read.csv('./data/film_category.csv', header=True, inferSchema=True)\n",
    "inventory_df = spark.read.csv('./data/inventory.csv', header=True, inferSchema=True)\n",
    "language_df = spark.read.csv('./data/language.csv', header=True, inferSchema=True)\n",
    "payment_df = spark.read.csv('./data/payment.csv', header=True, inferSchema=True)\n",
    "rental_df = spark.read.csv('./data/rental.csv', header=True, inferSchema=True)\n",
    "staff_df = spark.read.csv('./data/staff.csv', header=True, inferSchema=True)\n",
    "store_df = spark.read.csv('./data/store.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Домашнє завдання на тему Spark SQL\n",
    "\n",
    "Задачі з домашнього завдання на SQL потрібно розвʼязати за допомогою Spark SQL DataFrame API.\n",
    "\n",
    "- Дампи таблиць знаходяться в папці `data`. Датафрейми таблиць вже створені в клітинці вище.\n",
    "- Можете створювати стільки нових клітинок, скільки вам необхідно.\n",
    "- Розвʼязок кожної задачі має бути відображений в самому файлі (використати метод `.show()`)\n",
    "- код має бути оформлений у відповідності із одним із стилем, показаним лектором на занятті 13.\n",
    "\n",
    "**Увага!**\n",
    "Використовувати мову запитів SQL безпосередньо забороняється, потрібно використовувати виключно DataFrame API!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1.\n",
    "Вивести кількість фільмів в кожній категорії.\n",
    "Результат відсортувати за спаданням."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T11:13:27.572462Z",
     "start_time": "2024-05-24T11:13:27.346348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|category_id|count|\n",
      "+-----------+-----+\n",
      "|         15|   74|\n",
      "|          9|   73|\n",
      "|          8|   69|\n",
      "|          6|   68|\n",
      "|          2|   66|\n",
      "|          1|   64|\n",
      "|         13|   63|\n",
      "|          7|   62|\n",
      "|         10|   61|\n",
      "|         14|   61|\n",
      "|          3|   60|\n",
      "|          5|   58|\n",
      "|         16|   57|\n",
      "|          4|   57|\n",
      "|         11|   56|\n",
      "|         12|   51|\n",
      "+-----------+-----+\n"
     ]
    }
   ],
   "source": [
    "films_per_category = film_category_df.groupBy(\"category_id\").count()\n",
    "films_per_category.orderBy(F.col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "2.\n",
    "Вивести 10 акторів, чиї фільми брали на прокат найбільше.\n",
    "Результат відсортувати за спаданням."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T11:20:05.630561Z",
     "start_time": "2024-05-24T11:20:04.944966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----+\n",
      "|first_name|last_name|count|\n",
      "+----------+---------+-----+\n",
      "|       RIP| CRAWFORD|   34|\n",
      "|       TIM|  HACKMAN|   34|\n",
      "|      BURT|   TEMPLE|   34|\n",
      "|   KIRSTEN|   AKROYD|   34|\n",
      "|  CHARLIZE|    DENCH|   34|\n",
      "|      GARY|  PHOENIX|   34|\n",
      "|    WARREN|  JACKMAN|   33|\n",
      "|       TOM|  MIRANDA|   33|\n",
      "|     CHRIS|  BRIDGES|   33|\n",
      "|      JUDY|     DEAN|   33|\n",
      "+----------+---------+-----+\n"
     ]
    }
   ],
   "source": [
    "films_by_rental = (rental_df\n",
    "                   .join(inventory_df, on=\"inventory_id\")\n",
    "                   .groupBy(\"film_id\").count())\n",
    "popular_actors = (films_by_rental\n",
    "                  .join(film_actor_df, on=\"film_id\")\n",
    "                  .join(actor_df, on=\"actor_id\"))\n",
    "\n",
    "popular_actors.orderBy(F.col(\"count\").desc()).select(\"first_name\", \"last_name\", \"count\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "3.\n",
    "Вивести категорія фільмів, на яку було витрачено найбільше грошей\n",
    "в прокаті"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T11:28:57.071238Z",
     "start_time": "2024-05-24T11:28:56.525821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+\n",
      "|  name|      sum(amount)|\n",
      "+------+-----------------+\n",
      "|Sports|5314.209999999848|\n",
      "+------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "rental_categories_with_money = (rental_df\n",
    "                                .join(inventory_df, on=\"inventory_id\")\n",
    "                                .join(film_category_df, on=\"film_id\")\n",
    "                                .join(payment_df, on=\"rental_id\")\n",
    "                                .join(category_df, on=\"category_id\")\n",
    "                                .select(\"name\", \"amount\").groupBy(\"name\").sum())\n",
    "\n",
    "rental_categories_with_money.orderBy(F.col(\"sum(amount)\").desc()).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "4.\n",
    "Вивести назви фільмів, яких не має в inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T11:38:42.450602Z",
     "start_time": "2024-05-24T11:38:42.259126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               title|\n",
      "+--------------------+\n",
      "|      ALICE FANTASIA|\n",
      "|         APOLLO TEEN|\n",
      "|      ARGONAUTS TOWN|\n",
      "|       ARK RIDGEMONT|\n",
      "|ARSENIC INDEPENDENCE|\n",
      "|   BOONDOCK BALLROOM|\n",
      "|       BUTCH PANTHER|\n",
      "|       CATCH AMISTAD|\n",
      "| CHINATOWN GLADIATOR|\n",
      "|      CHOCOLATE DUCK|\n",
      "|COMMANDMENTS EXPRESS|\n",
      "|    CROSSING DIVORCE|\n",
      "|     CROWDS TELEMARK|\n",
      "|    CRYSTAL BREAKING|\n",
      "|          DAZED PUNK|\n",
      "|DELIVERANCE MULHO...|\n",
      "|   FIREHOUSE VIETNAM|\n",
      "|       FLOATS GARDEN|\n",
      "|FRANKENSTEIN STRA...|\n",
      "|  GLADIATOR WESTWARD|\n",
      "+--------------------+\n"
     ]
    }
   ],
   "source": [
    "non_inventory_films = film_df.join(inventory_df, on=\"film_id\", how=\"anti\")\n",
    "non_inventory_films.select(\"title\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "5.\n",
    "Вивести топ 3 актори, які найбільше зʼявлялись в категорії фільмів “Children”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-05-24T11:53:02.068047Z",
     "start_time": "2024-05-24T11:53:01.675690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|   full_name|\n",
      "+------------+\n",
      "|HELEN VOIGHT|\n",
      "| SUSAN DAVIS|\n",
      "|  MARY TANDY|\n",
      "+------------+\n"
     ]
    }
   ],
   "source": [
    "actors_child = (actor_df\n",
    "                      .join(film_actor_df, on=\"actor_id\")\n",
    "                      .join(film_category_df, on=\"film_id\")\n",
    "                      .join(category_df, on=\"category_id\")\n",
    "                      .filter(F.col(\"name\") == \"Children\")\n",
    "                      .withColumn(\"full_name\", F.concat(F.col(\"first_name\"), F.lit(\" \"), F.col(\"last_name\")))\n",
    "                      .groupBy(\"full_name\").count()\n",
    "                )\n",
    "\n",
    "actors_child.orderBy(F.col(\"count\").desc()).select(\"full_name\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Stop Spark session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T11:53:14.396032Z",
     "start_time": "2024-05-24T11:53:13.978351Z"
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
